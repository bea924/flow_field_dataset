{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "base_path = '../../'\n",
    "sys.path.append(base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "from flow_field_model import create_flow_field_model\n",
    "\n",
    "\n",
    "model = create_flow_field_model(input_shape=(32, 16, 16), out_channels=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1000 samples from 'datasets/pyvista-medium'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[33m2025-05-26 12:31:44.762 (   0.505s) [    725D3E3E1740]      vtkCGNSReader.cxx:4268  WARN| vtkCGNSReader (0x561c72c3cd70): Skipping BC_t node: BC_t type 'BCInflow' not supported yet.\u001b[0m\n",
      "\u001b[0m\u001b[33m2025-05-26 12:31:44.762 (   0.505s) [    725D3E3E1740]      vtkCGNSReader.cxx:4268  WARN| vtkCGNSReader (0x561c72c3cd70): Skipping BC_t node: BC_t type 'BCSymmetryPlane' not supported yet.\u001b[0m\n",
      "\u001b[0m\u001b[33m2025-05-26 12:31:44.762 (   0.505s) [    725D3E3E1740]      vtkCGNSReader.cxx:4268  WARN| vtkCGNSReader (0x561c72c3cd70): Skipping BC_t node: BC_t type 'BCTunnelOutflow' not supported yet.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05156abe254b476c81817fc3ba04d625",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Widget(value='<iframe src=\"http://localhost:41345/index.html?ui=P_0x725c018c9590_0&reconnect=auto\" class=\"pyvi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from src.pyvista_flow_field_dataset import PyvistaFlowFieldDataset\n",
    "ds_pv = PyvistaFlowFieldDataset.load_from_huggingface(num_samples=1000, data_dir='datasets/pyvista-medium')\n",
    "#ds_pv= PyvistaFlowFieldDataset.try_from_directory(\"datasets/pyvista-small\",1000)\n",
    "ds_pv[8].plot_volume(\"Pressure\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Voxelizing samples: 100%|██████████| 1000/1000 [00:00<00:00, 11818.64it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<src.voxel_flow_field_dataset.VoxelFlowFieldDataset at 0x725bd4bc2590>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.voxel_flow_field_dataset import VoxelFlowFieldDataset, VoxelFlowFieldDatasetConfig\n",
    "import torch.utils.data\n",
    "ds_voxel = VoxelFlowFieldDataset('datasets/voxels-medium',VoxelFlowFieldDatasetConfig(ds_pv, resolution=(32,16,16)))\n",
    "#s_voxel = VoxelFlowFieldDataset('datasets/voxels')\n",
    "ds_voxel.normalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train_samples = int(len(ds_voxel) * 0.8)\n",
    "num_val_samples = len(ds_voxel) - num_train_samples\n",
    "ds_voxel.shuffle()\n",
    "train_dataset = ds_voxel[:num_train_samples]\n",
    "val_dataset = ds_voxel[num_train_samples:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val_dataset[0].plot_slice(\"Mask\",slice_idx=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800, 200)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import torch.utils.data as data\n",
    "train_dataloader = data.DataLoader(train_dataset.get_default_loadable_dataset(), batch_size=16, shuffle=False, num_workers=0, pin_memory=True)\n",
    "val_dataloader = data.DataLoader(val_dataset.get_default_loadable_dataset(), batch_size=16, shuffle=False, num_workers=0, pin_memory=True)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "len(train_dataset), len(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 32, 16, 16])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_dataloader))[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Epoch 0/300, Loss: 9.733902273178101, Val Loss: 7.972622614640456\n",
      "Epoch 0/300, Loss: 4.189300466775894\n",
      "Epoch 1/300, Loss: 3.5883304077386855\n",
      "Epoch 2/300, Loss: 3.3997200483083727\n",
      "Epoch 3/300, Loss: 3.215679139494896\n",
      "Epoch 4/300, Loss: 3.2052409011125564\n",
      "Epoch 5/300, Loss: 3.16144626557827\n",
      "Epoch 6/300, Loss: 3.0632796835899354\n",
      "Epoch 7/300, Loss: 3.025746574997902\n",
      "Epoch 8/300, Loss: 3.059458538889885\n",
      "Epoch 9/300, Loss: 2.9621386164426804\n",
      "Epoch 10/300, Loss: 2.8630470776557924, Val Loss: 1.7349486075914824\n",
      "Epoch 10/300, Loss: 2.996861384510994\n",
      "Epoch 11/300, Loss: 2.853312212228775\n",
      "Epoch 12/300, Loss: 2.9268410432338716\n",
      "Epoch 13/300, Loss: 2.7389707446098326\n",
      "Epoch 14/300, Loss: 2.802820312976837\n",
      "Epoch 15/300, Loss: 2.6515990179777145\n",
      "Epoch 16/300, Loss: 2.5923105883598327\n",
      "Epoch 17/300, Loss: 2.500311992764473\n",
      "Epoch 18/300, Loss: 2.756461189389229\n",
      "Epoch 19/300, Loss: 2.568961184620857\n",
      "Epoch 20/300, Loss: 2.5184468162059783, Val Loss: 1.5615299435762258\n",
      "Epoch 20/300, Loss: 2.403886765241623\n",
      "Epoch 21/300, Loss: 2.3178561866283416\n",
      "Epoch 22/300, Loss: 2.2360687744617462\n",
      "Epoch 23/300, Loss: 2.1786361396312715\n",
      "Epoch 24/300, Loss: 2.200536367893219\n",
      "Epoch 25/300, Loss: 2.516262593269348\n",
      "Epoch 26/300, Loss: 2.2825650787353515\n",
      "Epoch 27/300, Loss: 2.094680513739586\n",
      "Epoch 28/300, Loss: 2.0918243992328645\n",
      "Epoch 29/300, Loss: 1.9584001886844635\n",
      "Epoch 30/300, Loss: 2.318005211353302, Val Loss: 1.9701453951688914\n",
      "Epoch 30/300, Loss: 2.005098810195923\n",
      "Epoch 31/300, Loss: 1.9610473495721816\n",
      "Epoch 32/300, Loss: 2.0505502873659136\n",
      "Epoch 33/300, Loss: 2.0609525030851366\n",
      "Epoch 34/300, Loss: 1.896008437871933\n",
      "Epoch 35/300, Loss: 2.0233918976783754\n",
      "Epoch 36/300, Loss: 2.1566204410791396\n",
      "Epoch 37/300, Loss: 1.9943887734413146\n",
      "Epoch 38/300, Loss: 1.8228714096546172\n",
      "Epoch 39/300, Loss: 1.9839690154790879\n",
      "Epoch 40/300, Loss: 2.1151691281795504, Val Loss: 1.6837920913329492\n",
      "Epoch 40/300, Loss: 2.0110774451494215\n",
      "Epoch 41/300, Loss: 2.114581738114357\n",
      "Epoch 42/300, Loss: 2.013433657884598\n",
      "Epoch 43/300, Loss: 1.7479656898975373\n",
      "Epoch 44/300, Loss: 1.7061488151550293\n",
      "Epoch 45/300, Loss: 1.6679529017210006\n",
      "Epoch 46/300, Loss: 1.6154048317670822\n",
      "Epoch 47/300, Loss: 1.5795829093456268\n",
      "Epoch 48/300, Loss: 1.5357146233320236\n",
      "Epoch 49/300, Loss: 1.498835362792015\n",
      "Epoch 50/300, Loss: 1.500639647245407, Val Loss: 1.6906886788514943\n",
      "Epoch 50/300, Loss: 1.4183684015274047\n",
      "Epoch 51/300, Loss: 1.352105035185814\n",
      "Epoch 52/300, Loss: 1.302687301635742\n",
      "Epoch 53/300, Loss: 1.333845711350441\n",
      "Epoch 54/300, Loss: 1.3426411300897598\n",
      "Epoch 55/300, Loss: 1.302853491306305\n",
      "Epoch 56/300, Loss: 1.2882335513830185\n",
      "Epoch 57/300, Loss: 1.2190880984067918\n",
      "Epoch 58/300, Loss: 1.2214996790885926\n",
      "Epoch 59/300, Loss: 1.1883846670389175\n",
      "Epoch 60/300, Loss: 1.2022676193714141, Val Loss: 1.4414833050507765\n",
      "Epoch 60/300, Loss: 1.1472113126516341\n",
      "Epoch 61/300, Loss: 1.0733390629291535\n",
      "Epoch 62/300, Loss: 1.0372523140907288\n",
      "Epoch 63/300, Loss: 1.0367209857702255\n",
      "Epoch 64/300, Loss: 1.0147814285755157\n",
      "Epoch 65/300, Loss: 0.9984307169914246\n",
      "Epoch 66/300, Loss: 1.0007827788591386\n",
      "Epoch 67/300, Loss: 0.9865825819969177\n",
      "Epoch 68/300, Loss: 0.9594753986597061\n",
      "Epoch 69/300, Loss: 0.9431731075048446\n",
      "Epoch 70/300, Loss: 0.974607543349266, Val Loss: 1.6758421613619878\n",
      "Epoch 70/300, Loss: 0.9295086294412613\n",
      "Epoch 71/300, Loss: 0.8942841386795044\n",
      "Epoch 72/300, Loss: 0.8795497864484787\n",
      "Epoch 73/300, Loss: 0.8811771363019943\n",
      "Epoch 74/300, Loss: 0.8876639086008072\n",
      "Epoch 75/300, Loss: 0.8951553604006768\n",
      "Epoch 76/300, Loss: 0.8451265698671341\n",
      "Epoch 77/300, Loss: 0.8503065469861031\n",
      "Epoch 78/300, Loss: 0.8350567829608917\n",
      "Epoch 79/300, Loss: 0.8555282384157181\n",
      "Epoch 80/300, Loss: 0.8396267032623291, Val Loss: 1.780694347161513\n",
      "Epoch 80/300, Loss: 0.8365949711203575\n",
      "Epoch 81/300, Loss: 0.818739615380764\n",
      "Epoch 82/300, Loss: 1.120554327070713\n",
      "Epoch 83/300, Loss: 1.020989453792572\n",
      "Epoch 84/300, Loss: 0.8852747714519501\n",
      "Epoch 85/300, Loss: 0.8522852233052254\n",
      "Epoch 86/300, Loss: 0.7742517623305321\n",
      "Epoch 87/300, Loss: 0.7542089056968689\n",
      "Epoch 88/300, Loss: 0.723432602584362\n",
      "Epoch 89/300, Loss: 0.7839425683021546\n",
      "Epoch 90/300, Loss: 0.8088064134120941, Val Loss: 1.6413563306515033\n",
      "Epoch 90/300, Loss: 0.9736451795697212\n",
      "Epoch 91/300, Loss: 0.9100848436355591\n",
      "Epoch 92/300, Loss: 0.8525046035647392\n",
      "Epoch 93/300, Loss: 0.7726581013202667\n",
      "Epoch 94/300, Loss: 0.6981946262717247\n",
      "Epoch 95/300, Loss: 0.6837753903865814\n",
      "Epoch 96/300, Loss: 0.7040891587734223\n",
      "Epoch 97/300, Loss: 0.6944531735777855\n",
      "Epoch 98/300, Loss: 0.6494031420350075\n",
      "Epoch 99/300, Loss: 0.6313306915760041\n",
      "Epoch 100/300, Loss: 0.6636458283662796, Val Loss: 1.9032759849841778\n",
      "Epoch 100/300, Loss: 0.6082460913062095\n",
      "Epoch 101/300, Loss: 0.6036221235990524\n",
      "Epoch 102/300, Loss: 0.5912254282832146\n",
      "Epoch 103/300, Loss: 0.5921252495050431\n",
      "Epoch 104/300, Loss: 0.5894355973601342\n",
      "Epoch 105/300, Loss: 0.5866721734404564\n",
      "Epoch 106/300, Loss: 0.6094827279448509\n",
      "Epoch 107/300, Loss: 0.6437134677171708\n",
      "Epoch 108/300, Loss: 0.6053851681947708\n",
      "Epoch 109/300, Loss: 0.643562541604042\n",
      "Epoch 110/300, Loss: 0.7907422626018524, Val Loss: 2.415096470942864\n",
      "Epoch 110/300, Loss: 0.75091085344553\n",
      "Epoch 111/300, Loss: 0.6874894800782204\n",
      "Epoch 112/300, Loss: 0.549994144141674\n",
      "Epoch 113/300, Loss: 0.5527034202218055\n",
      "Epoch 114/300, Loss: 0.5511805048584938\n",
      "Epoch 115/300, Loss: 0.524757798910141\n",
      "Epoch 116/300, Loss: 0.5179518672823906\n",
      "Epoch 117/300, Loss: 0.5115071561932564\n",
      "Epoch 118/300, Loss: 0.5486699947714806\n",
      "Epoch 119/300, Loss: 0.5681051021814346\n",
      "Epoch 120/300, Loss: 0.6290145128965378, Val Loss: 2.1820167899131775\n",
      "Epoch 120/300, Loss: 0.5584979596734047\n",
      "Epoch 121/300, Loss: 0.6677857765555382\n",
      "Epoch 122/300, Loss: 0.7995841816067696\n",
      "Epoch 123/300, Loss: 0.7155779445171356\n",
      "Epoch 124/300, Loss: 0.587589261829853\n",
      "Epoch 125/300, Loss: 0.561059381365776\n",
      "Epoch 126/300, Loss: 0.5133828696608543\n",
      "Epoch 127/300, Loss: 0.4971646502614021\n",
      "Epoch 128/300, Loss: 0.5624955189228058\n",
      "Epoch 129/300, Loss: 0.7785162156820298\n",
      "Epoch 130/300, Loss: 0.9913886117935181, Val Loss: 2.1429502230424147\n",
      "Epoch 130/300, Loss: 0.6347080770134926\n",
      "Epoch 131/300, Loss: 0.4784698933362961\n",
      "Epoch 132/300, Loss: 0.47829690247774126\n",
      "Epoch 133/300, Loss: 0.4732266166806221\n",
      "Epoch 134/300, Loss: 0.47061591893434523\n",
      "Epoch 135/300, Loss: 0.45651318967342375\n",
      "Epoch 136/300, Loss: 0.4510091072320938\n",
      "Epoch 137/300, Loss: 0.4546901282668114\n",
      "Epoch 138/300, Loss: 0.4724687737226486\n",
      "Epoch 139/300, Loss: 0.4572091618180275\n",
      "Epoch 140/300, Loss: 0.49242662638425827, Val Loss: 1.8767311985676105\n",
      "Epoch 140/300, Loss: 0.44006902068853376\n",
      "Epoch 141/300, Loss: 0.4501906818151474\n",
      "Epoch 142/300, Loss: 0.5502040070295334\n",
      "Epoch 143/300, Loss: 0.4940841290354729\n",
      "Epoch 144/300, Loss: 0.45651574730873107\n",
      "Epoch 145/300, Loss: 0.4629833474755287\n",
      "Epoch 146/300, Loss: 0.4381444227695465\n",
      "Epoch 147/300, Loss: 0.40834788113832476\n",
      "Epoch 148/300, Loss: 0.4000481814146042\n",
      "Epoch 149/300, Loss: 0.4084420865774155\n",
      "Epoch 150/300, Loss: 0.4268979370594025, Val Loss: 1.7779532395876372\n",
      "Epoch 150/300, Loss: 0.4141372227668762\n",
      "Epoch 151/300, Loss: 0.4074611499905586\n",
      "Epoch 152/300, Loss: 0.40897666811943056\n",
      "Epoch 153/300, Loss: 0.41434436619281767\n",
      "Epoch 154/300, Loss: 0.40601896911859514\n",
      "Epoch 155/300, Loss: 0.3949554547667503\n",
      "Epoch 156/300, Loss: 0.40509820222854614\n",
      "Epoch 157/300, Loss: 0.4153571480512619\n",
      "Epoch 158/300, Loss: 0.40682284742593766\n",
      "Epoch 159/300, Loss: 0.39844678848981857\n",
      "Epoch 160/300, Loss: 0.49470793068408964, Val Loss: 2.487443447113037\n",
      "Epoch 160/300, Loss: 0.44131052374839785\n",
      "Epoch 161/300, Loss: 0.5679392424225808\n",
      "Epoch 162/300, Loss: 0.5157766062021255\n",
      "Epoch 163/300, Loss: 0.427562812268734\n",
      "Epoch 164/300, Loss: 0.4219118738174438\n",
      "Epoch 165/300, Loss: 0.3964982283115387\n",
      "Epoch 166/300, Loss: 0.36966004729270935\n",
      "Epoch 167/300, Loss: 0.372584140598774\n",
      "Epoch 168/300, Loss: 0.3779589131474495\n",
      "Epoch 169/300, Loss: 0.3663610616326332\n",
      "Epoch 170/300, Loss: 0.4405594941973686, Val Loss: 2.7473467817673316\n",
      "Epoch 170/300, Loss: 0.35246262907981873\n",
      "Epoch 171/300, Loss: 0.35232048138976096\n",
      "Epoch 172/300, Loss: 0.387682526409626\n",
      "Epoch 173/300, Loss: 0.3767250561714172\n",
      "Epoch 174/300, Loss: 0.3695621877908707\n",
      "Epoch 175/300, Loss: 0.368712545633316\n",
      "Epoch 176/300, Loss: 0.3483493748307228\n",
      "Epoch 177/300, Loss: 0.3348486351966858\n",
      "Epoch 178/300, Loss: 0.34323083952069283\n",
      "Epoch 179/300, Loss: 0.36596178710460664\n",
      "Epoch 180/300, Loss: 0.39692912369966504, Val Loss: 1.7929135927787194\n",
      "Epoch 180/300, Loss: 0.3897852087020874\n",
      "Epoch 181/300, Loss: 0.39041698843240735\n",
      "Epoch 182/300, Loss: 0.3846750888228416\n",
      "Epoch 183/300, Loss: 0.47325389832258224\n",
      "Epoch 184/300, Loss: 0.5393063214421272\n",
      "Epoch 185/300, Loss: 0.49674334943294524\n",
      "Epoch 186/300, Loss: 0.4205058813095093\n",
      "Epoch 187/300, Loss: 0.39849294126033785\n",
      "Epoch 188/300, Loss: 0.351175851225853\n",
      "Epoch 189/300, Loss: 0.33139921993017196\n",
      "Epoch 190/300, Loss: 0.39430861204862594, Val Loss: 1.7186389290369475\n",
      "Epoch 190/300, Loss: 0.3210014744102955\n",
      "Epoch 191/300, Loss: 0.34102797374129296\n",
      "Epoch 192/300, Loss: 0.3291109023988247\n",
      "Epoch 193/300, Loss: 0.31071115031838414\n",
      "Epoch 194/300, Loss: 0.3092420993745327\n",
      "Epoch 195/300, Loss: 0.32718375042080877\n",
      "Epoch 196/300, Loss: 0.32319311767816544\n",
      "Epoch 197/300, Loss: 0.3282887949049473\n",
      "Epoch 198/300, Loss: 0.3562955518066883\n",
      "Epoch 199/300, Loss: 0.45799663946032526\n",
      "Epoch 200/300, Loss: 0.5075759762525558, Val Loss: 2.2259926062363844\n",
      "Epoch 200/300, Loss: 0.44702623948454856\n",
      "Epoch 201/300, Loss: 0.45312566697597506\n",
      "Epoch 202/300, Loss: 0.4276768478751183\n",
      "Epoch 203/300, Loss: 0.36606972604990007\n",
      "Epoch 204/300, Loss: 0.3159123899042606\n",
      "Epoch 205/300, Loss: 0.29946867197752\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 55\u001b[0m\n\u001b[1;32m     53\u001b[0m y \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m     54\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 55\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, y)\n\u001b[1;32m     57\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/Documents/flow_field_dataset/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/flow_field_dataset/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/flow_field_dataset/examples/voxel_data/flow_field_model.py:138\u001b[0m, in \u001b[0;36mFlowFieldUNet3D.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    135\u001b[0m skip_connections \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    137\u001b[0m \u001b[38;5;66;03m# Initial convolution\u001b[39;00m\n\u001b[0;32m--> 138\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    139\u001b[0m skip_connections\u001b[38;5;241m.\u001b[39mappend(x)\n\u001b[1;32m    141\u001b[0m \u001b[38;5;66;03m# Downsampling path\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/flow_field_dataset/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/flow_field_dataset/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/flow_field_dataset/examples/voxel_data/flow_field_model.py:27\u001b[0m, in \u001b[0;36mDoubleConv3D.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m---> 27\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdouble_conv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/flow_field_dataset/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/flow_field_dataset/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/flow_field_dataset/.venv/lib/python3.11/site-packages/torch/nn/modules/container.py:219\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 219\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/Documents/flow_field_dataset/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/flow_field_dataset/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/flow_field_dataset/.venv/lib/python3.11/site-packages/torch/nn/modules/conv.py:608\u001b[0m, in \u001b[0;36mConv3d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/flow_field_dataset/.venv/lib/python3.11/site-packages/torch/nn/modules/conv.py:603\u001b[0m, in \u001b[0;36mConv3d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    592\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv3d(\n\u001b[1;32m    593\u001b[0m         F\u001b[38;5;241m.\u001b[39mpad(\n\u001b[1;32m    594\u001b[0m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    601\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups,\n\u001b[1;32m    602\u001b[0m     )\n\u001b[0;32m--> 603\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv3d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    604\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\n\u001b[1;32m    605\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "print(f\"Using device: {device}\")\n",
    "model.to(device)\n",
    "criterion = nn.MSELoss()\n",
    "lr=5e-4\n",
    "epochs=300\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "#scheduler = lr_scheduler.ExponentialLR(optimizer, gamma=0.999)\n",
    "\n",
    "training_losses = []\n",
    "validation_losses = []\n",
    "logging_epochs = []\n",
    "\n",
    "    \n",
    "for epoch in range(epochs):\n",
    "    if (epoch) % 10 == 0:\n",
    "        val_loss = 0\n",
    "        train_loss_in_eval = 0\n",
    "        #model.eval()\n",
    "        with torch.no_grad():\n",
    "            for x, y in val_dataloader:\n",
    "                x, y = x.to(device), y.to(device)\n",
    "                x = x.float().unsqueeze(-1)\n",
    "                x = x.permute(0, 4, 1, 2, 3)\n",
    "                y = y.permute(0, 4, 1, 2, 3)\n",
    "                outputs = model(x)\n",
    "                loss = criterion(outputs, y)\n",
    "                val_loss += loss.item()\n",
    "            for x, y in train_dataloader:\n",
    "                x, y = x.to(device), y.to(device)\n",
    "                x = x.float().unsqueeze(-1)\n",
    "                x = x.permute(0, 4, 1, 2, 3)\n",
    "                y = y.permute(0, 4, 1, 2, 3)\n",
    "                outputs = model(x)\n",
    "                loss = criterion(outputs, y)\n",
    "                train_loss_in_eval += loss.item()\n",
    "\n",
    "\n",
    "        print(f\"Epoch {epoch}/{epochs}, Loss: {train_loss_in_eval / len(train_dataloader)}, Val Loss: {val_loss / len(val_dataloader)}\")\n",
    "        training_losses.append(train_loss_in_eval / len(train_dataloader))\n",
    "        validation_losses.append(val_loss / len(val_dataloader))\n",
    "        logging_epochs.append(epoch)\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for x,y in train_dataloader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        x=x.float().unsqueeze(-1)\n",
    "        x = x.permute(0, 4, 1, 2, 3)  # (N, D, H, W, C) → (N, C, D, H, W)\n",
    "        y = y.permute(0, 4, 1, 2, 3)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(x)\n",
    "        loss = criterion(outputs, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "    #scheduler.step()\n",
    "    print(f\"Epoch {epoch}/{epochs}, Loss: {epoch_loss / len(train_dataloader)}\")\n",
    "plt.plot(logging_epochs, training_losses, label='Training Loss')\n",
    "plt.plot(logging_epochs, validation_losses, label='Validation Loss')\n",
    "plt.legend()\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.yscale('log')\n",
    "plt.show()\n",
    "# Save the model\n",
    "torch.save(model.state_dict(), 'unet3d.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FlowFieldUNet3D(\n",
       "  (downs): ModuleList(\n",
       "    (0): Down3D(\n",
       "      (maxpool_conv): Sequential(\n",
       "        (0): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (1): DoubleConv3D(\n",
       "          (double_conv): Sequential(\n",
       "            (0): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "            (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "            (3): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "            (4): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (5): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): Down3D(\n",
       "      (maxpool_conv): Sequential(\n",
       "        (0): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (1): DoubleConv3D(\n",
       "          (double_conv): Sequential(\n",
       "            (0): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "            (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "            (3): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "            (4): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (5): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): Down3D(\n",
       "      (maxpool_conv): Sequential(\n",
       "        (0): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (1): DoubleConv3D(\n",
       "          (double_conv): Sequential(\n",
       "            (0): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "            (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "            (3): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "            (4): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (5): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (ups): ModuleList(\n",
       "    (0): Up3D(\n",
       "      (up): ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
       "      (conv): DoubleConv3D(\n",
       "        (double_conv): Sequential(\n",
       "          (0): Conv3d(256, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "          (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "          (4): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): Up3D(\n",
       "      (up): ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
       "      (conv): DoubleConv3D(\n",
       "        (double_conv): Sequential(\n",
       "          (0): Conv3d(128, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "          (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "          (4): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): Up3D(\n",
       "      (up): ConvTranspose3d(64, 32, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
       "      (conv): DoubleConv3D(\n",
       "        (double_conv): Sequential(\n",
       "          (0): Conv3d(64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "          (1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "          (4): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): Up3D(\n",
       "      (up): ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
       "      (conv): DoubleConv3D(\n",
       "        (double_conv): Sequential(\n",
       "          (0): Conv3d(160, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "          (1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "          (4): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (inc): DoubleConv3D(\n",
       "    (double_conv): Sequential(\n",
       "      (0): Conv3d(1, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (4): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (bottleneck): DoubleConv3D(\n",
       "    (double_conv): Sequential(\n",
       "      (0): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (4): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (outc): Conv3d(32, 5, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('unet3d.pth', map_location=device))\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask,y = next(iter(val_dataloader))\n",
    "mask = mask.to(device)\n",
    "y = y.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=mask.float().unsqueeze(-1)\n",
    "x = x.permute(0, 4, 1, 2, 3)  # (N, D, H, W, C) → (N, C, D, H, W)\n",
    "#y = y.permute(0, 4, 1, 2, 3)\n",
    "y_pred = model(x)\n",
    "y_pred = y_pred.permute(0, 2, 3, 4, 1)  # (N, C, D, H, W) → (N, D, H, W, C)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_sample = ds_voxel.prediction_to_sample(mask[0], y_pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.2570)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_sample.get_field(\"Pressure\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67759d13a343416082926035a6e498fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Widget(value='<iframe src=\"http://localhost:41345/index.html?ui=P_0x725bd41bce10_1&reconnect=auto\" class=\"pyvi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_sample.plot(\"Pressure\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94c2c333f0184cfbac4e435e64f3c5f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Widget(value='<iframe src=\"http://localhost:41345/index.html?ui=P_0x725bd5963950_2&reconnect=auto\" class=\"pyvi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "true_sample = ds_voxel.prediction_to_sample(mask[0], y[0])\n",
    "true_sample.plot(\"Pressure\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-0.3165), tensor(-0.2570))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_sample.get_field(\"Pressure\").mean(), pred_sample.get_field(\"Pressure\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.8368)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_sample.data[\"Pressure\"].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72246a95c0ca4a2c97414932532501bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=8, description='slice_idx', max=15), Output()), _dom_classes=('widget-in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_sample.plot_slice_interactively(\"Mask\",axis=\"z\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9601e6e5564b419e8ce6a62143ad2d9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=8, description='slice_idx', max=15), Output()), _dom_classes=('widget-in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "true_sample.plot_slice_interactively(\"Mask\", axis=\"z\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
