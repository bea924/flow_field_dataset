{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "base_path = '../../'\n",
    "sys.path.append(base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 50 samples from 'datasets/pyvista'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Graph(num_nodes=36577, num_edges=142478,\n",
       "      ndata_schemes={'BodyID': Scheme(shape=(), dtype=torch.int32), 'CellArea': Scheme(shape=(), dtype=torch.float32), 'Normal': Scheme(shape=(3,), dtype=torch.float32), 'ShearStress': Scheme(shape=(3,), dtype=torch.float32), 'Position': Scheme(shape=(3,), dtype=torch.float32), 'Temperature': Scheme(shape=(), dtype=torch.float32), 'Pressure': Scheme(shape=(), dtype=torch.float32)}\n",
       "      edata_schemes={'dx': Scheme(shape=(3,), dtype=torch.float32)})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.dgl_flow_field_dataset import DGLSurfaceFlowFieldDataset\n",
    "from src.pyvista_flow_field_dataset import PyvistaFlowFieldDataset\n",
    "ds_pv = PyvistaFlowFieldDataset.load_from_huggingface(\"datasets/pyvista\",num_samples=50)\n",
    "#ds_dgl = DGLSurfaceFlowFieldDataset(os.path.join(base_path,'datasets/dgl_surface'),ds_pv)\n",
    "ds_dgl = DGLSurfaceFlowFieldDataset(os.path.join(base_path,'datasets/dgl_surface'))\n",
    "ds_dgl[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train_samples = int(len(ds_dgl) * 0.8)\n",
    "num_val_samples = len(ds_dgl) - num_train_samples\n",
    "ds_dgl.shuffle()\n",
    "train_ds = ds_dgl.slice(0, num_train_samples)\n",
    "val_ds = ds_dgl.slice(num_train_samples, num_train_samples + num_val_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style='width: 100%;'><tr><th>Header</th><th>Data Arrays</th></tr><tr><td>\n",
       "<table style='width: 100%;'>\n",
       "<tr><th>UnstructuredGrid</th><th>Information</th></tr>\n",
       "<tr><td>N Cells</td><td>1002</td></tr>\n",
       "<tr><td>N Points</td><td>1042</td></tr>\n",
       "<tr><td>X Bounds</td><td>8.316e-02, 1.167e-01</td></tr>\n",
       "<tr><td>Y Bounds</td><td>9.825e-03, 4.827e-02</td></tr>\n",
       "<tr><td>Z Bounds</td><td>0.000e+00, 1.500e-02</td></tr>\n",
       "<tr><td>N Arrays</td><td>12</td></tr>\n",
       "</table>\n",
       "\n",
       "</td><td>\n",
       "<table style='width: 100%;'>\n",
       "<tr><th>Name</th><th>Field</th><th>Type</th><th>N Comp</th><th>Min</th><th>Max</th></tr>\n",
       "<tr><td>AreaMagnitude</td><td>Cells</td><td>float64</td><td>1</td><td>9.486e-07</td><td>3.866e-06</td></tr>\n",
       "<tr><td>HeatTransferCoefficient</td><td>Cells</td><td>float64</td><td>1</td><td>5.544e+00</td><td>4.480e+02</td></tr>\n",
       "<tr><td>Normal_0</td><td>Cells</td><td>float64</td><td>1</td><td>-1.000e+00</td><td>1.000e+00</td></tr>\n",
       "<tr><td>Normal_1</td><td>Cells</td><td>float64</td><td>1</td><td>-1.000e+00</td><td>1.000e+00</td></tr>\n",
       "<tr><td>Normal_2</td><td>Cells</td><td>float64</td><td>1</td><td>-1.000e+00</td><td>2.776e-14</td></tr>\n",
       "<tr><td>Pressure</td><td>Cells</td><td>float64</td><td>1</td><td>-1.881e+01</td><td>2.662e-01</td></tr>\n",
       "<tr><td>Temperature</td><td>Cells</td><td>float64</td><td>1</td><td>2.945e+02</td><td>2.945e+02</td></tr>\n",
       "<tr><td>WallShearStress_0</td><td>Cells</td><td>float64</td><td>1</td><td>-1.401e-01</td><td>4.478e-01</td></tr>\n",
       "<tr><td>WallShearStress_1</td><td>Cells</td><td>float64</td><td>1</td><td>-2.770e-01</td><td>3.552e-01</td></tr>\n",
       "<tr><td>WallShearStress_2</td><td>Cells</td><td>float64</td><td>1</td><td>-3.694e-01</td><td>2.998e-01</td></tr>\n",
       "<tr><td>Base/Zone</td><td>Fields</td><td><U16</td><td>1</td><td>nan</td><td>nan</td></tr>\n",
       "<tr><td>ispatch</td><td>Fields</td><td>int32</td><td>1</td><td>0.000e+00</td><td>0.000e+00</td></tr>\n",
       "</table>\n",
       "\n",
       "</td></tr> </table>"
      ],
      "text/plain": [
       "UnstructuredGrid (0x707f369b7dc0)\n",
       "  N Cells:    1002\n",
       "  N Points:   1042\n",
       "  X Bounds:   8.316e-02, 1.167e-01\n",
       "  Y Bounds:   9.825e-03, 4.827e-02\n",
       "  Z Bounds:   0.000e+00, 1.500e-02\n",
       "  N Arrays:   12"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_pv[1].surface_data[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyvista_ndarray([[0.498     , 0.        , 0.        ],\n",
       "                 [0.5       , 0.002     , 0.        ],\n",
       "                 [0.496     , 0.        , 0.        ],\n",
       "                 ...,\n",
       "                 [0.47394846, 0.08794846, 0.        ],\n",
       "                 [0.474     , 0.058     , 0.02      ],\n",
       "                 [0.47194449, 0.08594449, 0.        ]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_pv[0].get_surface_points(block_index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[33m2025-05-26 13:34:12.926 (   0.710s) [    7080E3A17740]      vtkCGNSReader.cxx:4268  WARN| vtkCGNSReader (0x64a44e732780): Skipping BC_t node: BC_t type 'BCInflow' not supported yet.\u001b[0m\n",
      "\u001b[0m\u001b[33m2025-05-26 13:34:12.926 (   0.710s) [    7080E3A17740]      vtkCGNSReader.cxx:4268  WARN| vtkCGNSReader (0x64a44e732780): Skipping BC_t node: BC_t type 'BCSymmetryPlane' not supported yet.\u001b[0m\n",
      "\u001b[0m\u001b[33m2025-05-26 13:34:12.926 (   0.710s) [    7080E3A17740]      vtkCGNSReader.cxx:4268  WARN| vtkCGNSReader (0x64a44e732780): Skipping BC_t node: BC_t type 'BCTunnelOutflow' not supported yet.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05310b1d7bbe496d91f5a1f49c614597",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Widget(value='<iframe src=\"http://localhost:36067/index.html?ui=P_0x707f368e5750_0&reconnect=auto\" class=\"pyvi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds_pv[1].plot_volume(\"Pressure\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Graph(num_nodes=35771, num_edges=139880,\n",
       "      ndata_schemes={'BodyID': Scheme(shape=(), dtype=torch.int32), 'CellArea': Scheme(shape=(), dtype=torch.float32), 'Normal': Scheme(shape=(3,), dtype=torch.float32), 'ShearStress': Scheme(shape=(3,), dtype=torch.float32), 'Position': Scheme(shape=(3,), dtype=torch.float32), 'Temperature': Scheme(shape=(), dtype=torch.float32), 'Pressure': Scheme(shape=(), dtype=torch.float32)}\n",
       "      edata_schemes={'dx': Scheme(shape=(3,), dtype=torch.float32)})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_dgl[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dgl.dataloading import GraphDataLoader\n",
    "import torch\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "dataloader = GraphDataLoader(train_ds, batch_size=1, shuffle=True)\n",
    "val_dataloader = GraphDataLoader(val_ds, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node X:  tensor([[-1.6407e+00,  1.4430e+00, -1.2733e+00,  4.5959e-03,  3.5109e-03,\n",
      "         -1.1739e+00],\n",
      "        [-1.6264e+00,  1.4430e+00, -1.2733e+00,  4.5959e-03,  3.5109e-03,\n",
      "         -1.1739e+00],\n",
      "        [-1.6407e+00,  1.3733e+00, -1.2733e+00,  4.5959e-03,  3.5109e-03,\n",
      "         -1.1739e+00],\n",
      "        ...,\n",
      "        [ 1.6980e+00, -1.4322e+00, -1.2313e+00,  4.2439e+00,  3.5109e-03,\n",
      "          1.2377e-02],\n",
      "        [ 1.6980e+00, -1.3734e+00, -1.2613e+00,  4.2439e+00,  3.5109e-03,\n",
      "          1.2377e-02],\n",
      "        [ 1.6980e+00, -1.4322e+00, -1.2613e+00,  4.2439e+00,  3.5109e-03,\n",
      "          1.2377e-02]]) torch.Size([35771, 6])\n",
      "Edge X:  tensor([[ 1.5488e+00,  4.0420e-10,  2.5981e-10],\n",
      "        [-3.2793e-10, -1.9337e+00,  2.5981e-10],\n",
      "        [-1.5488e+00,  4.0420e-10,  2.5981e-10],\n",
      "        ...,\n",
      "        [-3.2793e-10, -1.6311e+00,  2.5981e-10],\n",
      "        [-3.2793e-10,  4.0420e-10,  4.4761e-01],\n",
      "        [-3.2793e-10,  1.6311e+00,  2.5981e-10]]) torch.Size([139880, 3])\n",
      "Node Y:  tensor([[ 1.3031e-01, -6.6680e-01,  9.2780e-02,  7.6789e-03, -3.7723e-02],\n",
      "        [ 1.2526e-01, -6.6647e-01, -2.9992e-01,  4.7583e-03, -3.7723e-02],\n",
      "        [ 1.3143e-01, -6.6668e-01,  1.0376e-01,  4.7667e-02, -3.7723e-02],\n",
      "        ...,\n",
      "        [-1.5084e-01, -6.5300e-01, -4.9037e-01,  2.5351e-05, -3.7723e-02],\n",
      "        [-1.5084e-01, -6.5005e-01, -4.9037e-01,  2.5351e-05, -3.7723e-02],\n",
      "        [-1.5084e-01, -6.5297e-01, -4.9037e-01,  2.5351e-05, -3.7723e-02]]) torch.Size([35771, 5])\n"
     ]
    }
   ],
   "source": [
    "import dgl\n",
    "\n",
    "\n",
    "def get_node_edge_X(graph: dgl.DGLGraph):\n",
    "    node_X = torch.cat([graph.ndata[\"Position\"], graph.ndata[\"Normal\"]],dim=1)\n",
    "    edge_X = torch.cat([graph.edata[\"dx\"]],dim=1)\n",
    "    return node_X, edge_X\n",
    "\n",
    "def get_node_Y(graph: dgl.DGLGraph):\n",
    "    return torch.cat([graph.ndata[\"Pressure\"].unsqueeze(1),graph.ndata[\"Temperature\"].unsqueeze(1),graph.ndata['ShearStress']],dim=1)\n",
    "\n",
    "def set_graph_features(graph: dgl.DGLGraph, node_X, edge_X, node_Y):\n",
    "    graph.ndata[\"Position\"] = node_X[:,:3]\n",
    "    graph.ndata[\"Normal\"] = node_X[:,3:]\n",
    "    graph.edata[\"dx\"] = edge_X\n",
    "    graph.ndata[\"Pressure\"] = node_Y[:,0]\n",
    "    graph.ndata[\"Temperature\"] = node_Y[:,1]\n",
    "    graph.ndata[\"ShearStress\"] = node_Y[:,2:]\n",
    "g=ds_dgl[0]\n",
    "g_cp=g.clone()\n",
    "ndx, edx = get_node_edge_X(g)\n",
    "ndy = get_node_Y(g)\n",
    "set_graph_features(g_cp, ndx, edx, ndy)\n",
    "assert torch.allclose(g_cp.ndata[\"Position\"], g.ndata[\"Position\"])\n",
    "assert torch.allclose(g_cp.ndata[\"Normal\"], g.ndata[\"Normal\"])\n",
    "assert torch.allclose(g_cp.edata[\"dx\"], g.edata[\"dx\"])\n",
    "assert torch.allclose(g_cp.ndata[\"Pressure\"], g.ndata[\"Pressure\"])\n",
    "assert torch.allclose(g_cp.ndata[\"Temperature\"], g.ndata[\"Temperature\"])\n",
    "assert torch.allclose(g_cp.ndata[\"ShearStress\"], g.ndata[\"ShearStress\"])\n",
    "num_node_features = ndx.shape[1]\n",
    "num_edge_features = edx.shape[1]\n",
    "num_node_labels = ndy.shape[1]\n",
    "print(\"Node X: \",ndx, ndx.shape)\n",
    "print(\"Edge X: \",edx, edx.shape)\n",
    "print(\"Node Y: \",ndy, ndy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modulus.models.meshgraphnet import MeshGraphNet\n",
    "model = MeshGraphNet(\n",
    "    input_dim_nodes=num_node_features,\n",
    "    input_dim_edges=num_edge_features,\n",
    "    output_dim=num_node_labels,\n",
    "    aggregation='sum',\n",
    "    hidden_dim_edge_encoder=64,\n",
    "    hidden_dim_node_encoder=64,\n",
    "    hidden_dim_processor=64,\n",
    "    hidden_dim_node_decoder=64\n",
    ")\n",
    "model=model.to(device)\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "from torch.amp import GradScaler\n",
    "optimizer = Adam(model.parameters(), lr=1e-4)\n",
    "scheduler = LambdaLR(optimizer, lr_lambda=lambda epoch: 0.99985 ** epoch)\n",
    "scaler = GradScaler(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[91mCould not find valid model file /home/olep/Documents/flow_field_dataset/examples/meshgraphnet/checkpoints/MeshGraphNet.0.0.mdlus, skipping load\u001b[0m\n",
      "\u001b[93mCould not find valid checkpoint file, skipping load\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 loss: 1.046351133659482 val_loss: 0.4740852639079094\n",
      "Epoch 1 loss: 0.9650482021272182 val_loss: 0.4349715456366539\n",
      "Epoch 2 loss: 0.9458094319328666 val_loss: 0.46294390261173246\n",
      "Epoch 3 loss: 0.939226520806551 val_loss: 0.4319621011614799\n",
      "Epoch 4 loss: 0.9239674463868142 val_loss: 0.44288818538188934\n",
      "Epoch 5 loss: 0.9217682892456651 val_loss: 0.42642504572868345\n",
      "Epoch 6 loss: 0.930337182059884 val_loss: 0.4440990313887596\n",
      "Epoch 7 loss: 0.9196593062952161 val_loss: 0.4646159097552299\n",
      "Epoch 8 loss: 0.9383936071768403 val_loss: 0.4425138980150223\n",
      "Epoch 9 loss: 0.9097407344728708 val_loss: 0.42522486448287966\n",
      "Epoch 10 loss: 0.9167431684210896 val_loss: 0.4466161772608757\n",
      "Epoch 11 loss: 0.9151038797572255 val_loss: 0.44791983515024186\n",
      "Epoch 12 loss: 0.9092549813911319 val_loss: 0.4503635555505753\n",
      "Epoch 13 loss: 0.9124904556199909 val_loss: 0.444341616332531\n",
      "Epoch 14 loss: 0.8948028875514865 val_loss: 0.4194667488336563\n",
      "Epoch 15 loss: 0.8952676793560386 val_loss: 0.44865152090787885\n",
      "Epoch 16 loss: 0.885750824958086 val_loss: 0.4243870571255684\n",
      "Epoch 17 loss: 0.8894527310505509 val_loss: 0.44647628217935564\n",
      "Epoch 18 loss: 0.9213560996577144 val_loss: 0.4331274703145027\n",
      "Epoch 19 loss: 0.8939769402146339 val_loss: 0.4310623198747635\n",
      "Epoch 20 loss: 0.8942009853199124 val_loss: 0.41914201229810716\n",
      "Epoch 21 loss: 0.8943743597716093 val_loss: 0.42024026066064835\n",
      "Epoch 22 loss: 0.8842039270326495 val_loss: 0.4446482822299004\n",
      "Epoch 23 loss: 0.8793767826631665 val_loss: 0.4233799621462822\n",
      "Epoch 24 loss: 0.8777738371863961 val_loss: 0.4536060854792595\n",
      "Epoch 25 loss: 0.8768924666568637 val_loss: 0.4239308759570122\n",
      "Epoch 26 loss: 0.8849574415013194 val_loss: 0.4223144918680191\n",
      "Epoch 27 loss: 0.8744260488077998 val_loss: 0.4486898943781853\n",
      "Epoch 28 loss: 0.8767168525606394 val_loss: 0.4288606643676758\n",
      "Epoch 29 loss: 0.8843396607786417 val_loss: 0.44175818264484407\n",
      "Epoch 30 loss: 0.8889152856543661 val_loss: 0.44166678190231323\n",
      "Epoch 31 loss: 0.8842646596953273 val_loss: 0.4310555040836334\n",
      "Epoch 32 loss: 0.8746420113369823 val_loss: 0.43594426810741427\n",
      "Epoch 33 loss: 0.8709387715905905 val_loss: 0.417740136384964\n",
      "Epoch 34 loss: 0.8864685282111168 val_loss: 0.4511026218533516\n",
      "Epoch 35 loss: 0.8629422567784786 val_loss: 0.4136733442544937\n",
      "Epoch 36 loss: 0.863542327284813 val_loss: 0.4324046239256859\n",
      "Epoch 37 loss: 0.8693828890100121 val_loss: 0.42190922498703004\n",
      "Epoch 38 loss: 0.8701272618025542 val_loss: 0.441175377368927\n",
      "Epoch 39 loss: 0.8731960998848081 val_loss: 0.4557013034820557\n",
      "Epoch 40 loss: 0.8907955408096313 val_loss: 0.43235054761171343\n",
      "Epoch 41 loss: 0.8782211223617196 val_loss: 0.40743279457092285\n",
      "Epoch 42 loss: 0.8652913019061088 val_loss: 0.428107938170433\n",
      "Epoch 43 loss: 0.8620519917458296 val_loss: 0.42602109014987943\n",
      "Epoch 44 loss: 0.8543834548443556 val_loss: 0.4244306892156601\n",
      "Epoch 45 loss: 0.8511414118111134 val_loss: 0.4220674932003021\n",
      "Epoch 46 loss: 0.8590443000197411 val_loss: 0.4419584199786186\n",
      "Epoch 47 loss: 0.8553350333124399 val_loss: 0.44118233025074005\n",
      "Epoch 48 loss: 0.8554119670763611 val_loss: 0.43882849663496015\n",
      "Epoch 49 loss: 0.8709307035431266 val_loss: 0.44982321560382843\n",
      "Epoch 50 loss: 0.8757084872573614 val_loss: 0.43691976368427277\n",
      "Epoch 51 loss: 0.8611985977739096 val_loss: 0.43055042773485186\n",
      "Epoch 52 loss: 0.8553477223962546 val_loss: 0.4217522695660591\n",
      "Epoch 53 loss: 0.851915325038135 val_loss: 0.4248919978737831\n",
      "Epoch 54 loss: 0.8435755817219615 val_loss: 0.42938500791788103\n",
      "Epoch 55 loss: 0.8471879379823803 val_loss: 0.42797781676054003\n",
      "Epoch 56 loss: 0.8558132169768214 val_loss: 0.453243488073349\n",
      "Epoch 57 loss: 0.8474942494183779 val_loss: 0.42899846136569975\n",
      "Epoch 58 loss: 0.8392908453941346 val_loss: 0.4396486818790436\n",
      "Epoch 59 loss: 0.8427112698554993 val_loss: 0.4181949317455292\n",
      "Epoch 60 loss: 0.8469213841482996 val_loss: 0.43769119679927826\n",
      "Epoch 61 loss: 0.8704197596758604 val_loss: 0.4287047892808914\n",
      "Epoch 62 loss: 0.8381419532001019 val_loss: 0.44585864841938017\n",
      "Epoch 63 loss: 0.8596599524840712 val_loss: 0.42098135203123094\n",
      "Epoch 64 loss: 0.8579073134809733 val_loss: 0.432571305334568\n",
      "Epoch 65 loss: 0.8632182132452726 val_loss: 0.40854250341653825\n",
      "Epoch 66 loss: 0.8475419152528048 val_loss: 0.411396948993206\n",
      "Epoch 67 loss: 0.8592500964179635 val_loss: 0.4239365816116333\n",
      "Epoch 68 loss: 0.8395802626386285 val_loss: 0.4500033661723137\n",
      "Epoch 69 loss: 0.8506050551310181 val_loss: 0.4181405767798424\n",
      "Epoch 70 loss: 0.8591010069474578 val_loss: 0.41992218494415284\n",
      "Epoch 71 loss: 0.8679898239672184 val_loss: 0.41929689347743987\n",
      "Epoch 72 loss: 0.8498256132006645 val_loss: 0.4339180693030357\n",
      "Epoch 73 loss: 0.8667882060632109 val_loss: 0.4112306788563728\n",
      "Epoch 74 loss: 0.8478509375825525 val_loss: 0.42408320903778074\n",
      "Epoch 75 loss: 0.8269537830725312 val_loss: 0.42447897493839265\n",
      "Epoch 76 loss: 0.8274801081046462 val_loss: 0.43419400602579117\n",
      "Epoch 77 loss: 0.835515146329999 val_loss: 0.4379581227898598\n",
      "Epoch 78 loss: 0.8388565396890044 val_loss: 0.4244236916303635\n",
      "Epoch 79 loss: 0.8331535192206502 val_loss: 0.41304178684949877\n",
      "Epoch 80 loss: 0.8327254699543118 val_loss: 0.42737862318754194\n",
      "Epoch 81 loss: 0.8189427431672811 val_loss: 0.40803181678056716\n",
      "Epoch 82 loss: 0.8271827030926943 val_loss: 0.42198578715324403\n",
      "Epoch 83 loss: 0.8296289740130305 val_loss: 0.43486498296260834\n",
      "Epoch 84 loss: 0.8254944493994116 val_loss: 0.42712302356958387\n",
      "Epoch 85 loss: 0.8243186639621853 val_loss: 0.43869817852973936\n",
      "Epoch 86 loss: 0.8211626335978508 val_loss: 0.42983892261981965\n",
      "Epoch 87 loss: 0.8238196540623903 val_loss: 0.4175293579697609\n",
      "Epoch 88 loss: 0.8396910829469562 val_loss: 0.42326363921165466\n",
      "Epoch 89 loss: 0.8320413641631603 val_loss: 0.42146545350551606\n",
      "Epoch 90 loss: 0.8179163947701454 val_loss: 0.43072354346513747\n",
      "Epoch 91 loss: 0.8109284875914454 val_loss: 0.434327994287014\n",
      "Epoch 92 loss: 0.8188097268342972 val_loss: 0.4133807510137558\n",
      "Epoch 93 loss: 0.822234277613461 val_loss: 0.42215428352355955\n",
      "Epoch 94 loss: 0.828377416729927 val_loss: 0.4160762995481491\n",
      "Epoch 95 loss: 0.8322466541081667 val_loss: 0.4172442466020584\n",
      "Epoch 96 loss: 0.825328740477562 val_loss: 0.4210045799612999\n",
      "Epoch 97 loss: 0.8274942670017481 val_loss: 0.4189471736550331\n",
      "Epoch 98 loss: 0.8287978840991854 val_loss: 0.42288830429315566\n",
      "Epoch 99 loss: 0.8388702768832446 val_loss: 0.43166670203208923\n",
      "Epoch 100 loss: 0.8173915782943368 val_loss: 0.4377221643924713\n",
      "Epoch 101 loss: 0.8246717609465122 val_loss: 0.4290450856089592\n",
      "Epoch 102 loss: 0.8198719443753362 val_loss: 0.4174809232354164\n",
      "Epoch 103 loss: 0.8153176587074995 val_loss: 0.41573757529258726\n",
      "Epoch 104 loss: 0.8249708700925111 val_loss: 0.4243948355317116\n",
      "Epoch 105 loss: 0.826800468377769 val_loss: 0.435358963906765\n",
      "Epoch 106 loss: 0.8091198304668069 val_loss: 0.4297977417707443\n",
      "Epoch 107 loss: 0.8091432120651006 val_loss: 0.4360185369849205\n",
      "Epoch 108 loss: 0.8157655702903867 val_loss: 0.42870919555425646\n",
      "Epoch 109 loss: 0.8043044025078416 val_loss: 0.42988796085119246\n",
      "Epoch 110 loss: 0.8127905670553446 val_loss: 0.41726548224687576\n",
      "Epoch 111 loss: 0.8201625583693385 val_loss: 0.4431609004735947\n",
      "Epoch 112 loss: 0.8368610672652721 val_loss: 0.430487559735775\n",
      "Epoch 113 loss: 0.825066182948649 val_loss: 0.4212501600384712\n",
      "Epoch 114 loss: 0.8063071932643652 val_loss: 0.42980011105537413\n",
      "Epoch 115 loss: 0.8084470212459565 val_loss: 0.43422804623842237\n",
      "Epoch 116 loss: 0.7988690873607993 val_loss: 0.41616002917289735\n",
      "Epoch 117 loss: 0.8042994197458029 val_loss: 0.4425627216696739\n",
      "Epoch 118 loss: 0.8303230239078403 val_loss: 0.46413824409246446\n",
      "Epoch 119 loss: 0.8564585192129016 val_loss: 0.44165994971990585\n",
      "Epoch 120 loss: 0.8232054064050317 val_loss: 0.42441518753767016\n",
      "Epoch 121 loss: 0.8245976677164435 val_loss: 0.42830572426319125\n",
      "Epoch 122 loss: 0.8131645703688264 val_loss: 0.43129112720489504\n",
      "Epoch 123 loss: 0.8084990005940199 val_loss: 0.4237640455365181\n",
      "Epoch 124 loss: 0.8068478746339679 val_loss: 0.41864802688360214\n",
      "Epoch 125 loss: 0.8021694324910641 val_loss: 0.4230924353003502\n",
      "Epoch 126 loss: 0.8037458501756192 val_loss: 0.4267429456114769\n",
      "Epoch 127 loss: 0.7966623270884157 val_loss: 0.4340153679251671\n",
      "Epoch 128 loss: 0.7969873668625951 val_loss: 0.43191403746604917\n",
      "Epoch 129 loss: 0.811725215613842 val_loss: 0.4320428729057312\n",
      "Epoch 130 loss: 0.8013231731951237 val_loss: 0.4200597867369652\n",
      "Epoch 131 loss: 0.8035639794543386 val_loss: 0.4272025540471077\n",
      "Epoch 132 loss: 0.7961631074547768 val_loss: 0.43653077632188797\n",
      "Epoch 133 loss: 0.8048727294430137 val_loss: 0.4357966870069504\n",
      "Epoch 134 loss: 0.7958316307514905 val_loss: 0.41710124611854554\n",
      "Epoch 135 loss: 0.800510692037642 val_loss: 0.430820868909359\n",
      "Epoch 136 loss: 0.787016605772078 val_loss: 0.4200385853648186\n",
      "Epoch 137 loss: 0.788201087154448 val_loss: 0.4398726046085358\n",
      "Epoch 138 loss: 0.805454121157527 val_loss: 0.4371313497424126\n",
      "Epoch 139 loss: 0.8117659587413073 val_loss: 0.41884017288684844\n",
      "Epoch 140 loss: 0.818434645421803 val_loss: 0.426235269010067\n",
      "Epoch 141 loss: 0.8077401012182236 val_loss: 0.43318958282470704\n",
      "Epoch 142 loss: 0.7980479804798961 val_loss: 0.42774280309677126\n",
      "Epoch 143 loss: 0.7891449112445116 val_loss: 0.4355341777205467\n",
      "Epoch 144 loss: 0.7853509863838554 val_loss: 0.4295791685581207\n",
      "Epoch 145 loss: 0.8128713890910149 val_loss: 0.4401589706540108\n",
      "Epoch 146 loss: 0.8020350141450763 val_loss: 0.41949519962072374\n",
      "Epoch 147 loss: 0.791473027318716 val_loss: 0.4304392457008362\n",
      "Epoch 148 loss: 0.7862104818224906 val_loss: 0.4379327520728111\n",
      "Epoch 149 loss: 0.7833775686100125 val_loss: 0.4588122218847275\n",
      "Epoch 150 loss: 0.7836773915216326 val_loss: 0.4319145143032074\n",
      "Epoch 151 loss: 0.8013262173160911 val_loss: 0.44023440927267077\n",
      "Epoch 152 loss: 0.7914380978792905 val_loss: 0.4328344389796257\n",
      "Epoch 153 loss: 0.7865853460505605 val_loss: 0.42685981541872026\n",
      "Epoch 154 loss: 0.779147507250309 val_loss: 0.42582134902477264\n",
      "Epoch 155 loss: 0.7920624379068613 val_loss: 0.44022716879844664\n",
      "Epoch 156 loss: 0.7887942913919688 val_loss: 0.4414896681904793\n",
      "Epoch 157 loss: 0.7800180058926344 val_loss: 0.44055346250534055\n",
      "Epoch 158 loss: 0.7761766323819757 val_loss: 0.43923705220222475\n",
      "Epoch 159 loss: 0.7789569299668073 val_loss: 0.4360082924365997\n",
      "Epoch 160 loss: 0.786287971585989 val_loss: 0.45788097828626634\n",
      "Epoch 161 loss: 0.7951961612328887 val_loss: 0.4338679417967796\n",
      "Epoch 162 loss: 0.7800265958532691 val_loss: 0.4377771496772766\n",
      "Epoch 163 loss: 0.7904987020418048 val_loss: 0.4241928145289421\n",
      "Epoch 164 loss: 0.8256926130503416 val_loss: 0.4256580263376236\n",
      "Epoch 165 loss: 0.7875691534951329 val_loss: 0.43110926598310473\n",
      "Epoch 166 loss: 0.792974298633635 val_loss: 0.42716932743787767\n",
      "Epoch 167 loss: 0.8021459268406034 val_loss: 0.4293946877121925\n",
      "Epoch 168 loss: 0.7870203806087375 val_loss: 0.4401782974600792\n",
      "Epoch 169 loss: 0.7924755858257413 val_loss: 0.42355943769216536\n",
      "Epoch 170 loss: 0.7902769673615694 val_loss: 0.4257893741130829\n",
      "Epoch 171 loss: 0.7731191333383322 val_loss: 0.43777130991220475\n",
      "Epoch 172 loss: 0.7816916273906827 val_loss: 0.46827777177095414\n",
      "Epoch 173 loss: 0.7751147078350187 val_loss: 0.4299270957708359\n",
      "Epoch 174 loss: 0.7764535706490279 val_loss: 0.4303123980760574\n",
      "Epoch 175 loss: 0.8042178837582469 val_loss: 0.4556333005428314\n",
      "Epoch 176 loss: 0.8013518324121833 val_loss: 0.4335085034370422\n",
      "Epoch 177 loss: 0.7843068033456803 val_loss: 0.4438435107469559\n",
      "Epoch 178 loss: 0.7719004955142736 val_loss: 0.4394529640674591\n",
      "Epoch 179 loss: 0.7748867491260171 val_loss: 0.4332558140158653\n",
      "Epoch 180 loss: 0.7702543245628476 val_loss: 0.44911040663719176\n",
      "Epoch 181 loss: 0.7681074377149344 val_loss: 0.4298241749405861\n",
      "Epoch 182 loss: 0.765277749300003 val_loss: 0.43348597139120104\n",
      "Epoch 183 loss: 0.7895025059580802 val_loss: 0.4437528595328331\n",
      "Epoch 184 loss: 0.777954625710845 val_loss: 0.43826936930418015\n",
      "Epoch 185 loss: 0.7759522769600153 val_loss: 0.43000765442848204\n",
      "Epoch 186 loss: 0.7947164449840785 val_loss: 0.45287979394197464\n",
      "Epoch 187 loss: 0.7835007818415761 val_loss: 0.4406499952077866\n",
      "Epoch 188 loss: 0.7736756604164838 val_loss: 0.42526848465204237\n",
      "Epoch 189 loss: 0.7742215223610401 val_loss: 0.4357184484601021\n",
      "Epoch 190 loss: 0.7752539042383433 val_loss: 0.431266276538372\n",
      "Epoch 191 loss: 0.7713494779542088 val_loss: 0.4282671496272087\n",
      "Epoch 192 loss: 0.7740847213193774 val_loss: 0.42974830567836764\n",
      "Epoch 193 loss: 0.7799485249444842 val_loss: 0.44932919293642043\n",
      "Epoch 194 loss: 0.7730968400835991 val_loss: 0.44064763337373736\n",
      "Epoch 195 loss: 0.7814545745030046 val_loss: 0.4446864426136017\n",
      "Epoch 196 loss: 0.7643650788813829 val_loss: 0.4423163324594498\n",
      "Epoch 197 loss: 0.7633841818198561 val_loss: 0.4475619554519653\n",
      "Epoch 198 loss: 0.7567824313417078 val_loss: 0.45040925294160844\n",
      "Epoch 199 loss: 0.7511793898418546 val_loss: 0.44572593569755553\n",
      "Epoch 200 loss: 0.761481816880405 val_loss: 0.4409820392727852\n",
      "Epoch 201 loss: 0.7745596965774894 val_loss: 0.43059330731630324\n",
      "Epoch 202 loss: 0.8688296806067228 val_loss: 0.4575091376900673\n",
      "Epoch 203 loss: 0.8052916632965207 val_loss: 0.4204047203063965\n",
      "Epoch 204 loss: 0.78873599357903 val_loss: 0.4358338177204132\n",
      "Epoch 205 loss: 0.7723759487271309 val_loss: 0.43648952543735503\n",
      "Epoch 206 loss: 0.7677549090236425 val_loss: 0.4351422116160393\n",
      "Epoch 207 loss: 0.7658672830089926 val_loss: 0.44040463119745255\n",
      "Epoch 208 loss: 0.7772825324907899 val_loss: 0.4331680998206139\n",
      "Epoch 209 loss: 0.7818631643429399 val_loss: 0.4307687297463417\n",
      "Epoch 210 loss: 0.7822743289172649 val_loss: 0.43572180420160295\n",
      "Epoch 211 loss: 0.763456049375236 val_loss: 0.45526878386735914\n",
      "Epoch 212 loss: 0.7784299965947866 val_loss: 0.43589833080768586\n",
      "Epoch 213 loss: 0.7667322240769863 val_loss: 0.4310978174209595\n",
      "Epoch 214 loss: 0.7566576903685928 val_loss: 0.45923654437065126\n",
      "Epoch 215 loss: 0.7615858484059572 val_loss: 0.4373348906636238\n",
      "Epoch 216 loss: 0.7608821850270033 val_loss: 0.4252898171544075\n",
      "Epoch 217 loss: 0.7542116632685065 val_loss: 0.44322706013917923\n",
      "Epoch 218 loss: 0.7586828170344233 val_loss: 0.45180235654115675\n",
      "Epoch 219 loss: 0.755325534939766 val_loss: 0.4462086096405983\n",
      "Epoch 220 loss: 0.7458103284239769 val_loss: 0.45944578647613527\n",
      "Epoch 221 loss: 0.7539490817114711 val_loss: 0.442875400185585\n",
      "Epoch 222 loss: 0.7542771240696311 val_loss: 0.45539441853761675\n",
      "Epoch 223 loss: 0.7519410310313106 val_loss: 0.45500963032245634\n",
      "Epoch 224 loss: 0.7498412130400538 val_loss: 0.4446409896016121\n",
      "Epoch 225 loss: 0.7602466767653823 val_loss: 0.4388793662190437\n",
      "Epoch 226 loss: 0.7674859505146742 val_loss: 0.43863224536180495\n",
      "Epoch 227 loss: 0.7651762021705508 val_loss: 0.4519574508070946\n",
      "Epoch 228 loss: 0.7508818997070194 val_loss: 0.4399926945567131\n",
      "Epoch 229 loss: 0.7461126731708646 val_loss: 0.4596865981817245\n",
      "Epoch 230 loss: 0.7432662341743708 val_loss: 0.4553041115403175\n",
      "Epoch 231 loss: 0.7531866990029812 val_loss: 0.44613673686981203\n",
      "Epoch 232 loss: 0.7483422741293907 val_loss: 0.4762556806206703\n",
      "Epoch 233 loss: 0.7515142563730478 val_loss: 0.4488898515701294\n",
      "Epoch 234 loss: 0.7522498823702335 val_loss: 0.4441820755600929\n",
      "Epoch 235 loss: 0.7798948790878057 val_loss: 0.41723063588142395\n",
      "Epoch 236 loss: 0.7543351834639906 val_loss: 0.4472544103860855\n",
      "Epoch 237 loss: 0.7636481244117022 val_loss: 0.43259486854076384\n",
      "Epoch 238 loss: 0.7520385634154081 val_loss: 0.4393812775611877\n",
      "Epoch 239 loss: 0.7616657482460141 val_loss: 0.4520042508840561\n",
      "Epoch 240 loss: 0.7783774707466364 val_loss: 0.4434948071837425\n",
      "Epoch 241 loss: 0.7488140694797039 val_loss: 0.43406598567962645\n",
      "Epoch 242 loss: 0.7525556927546859 val_loss: 0.4412595942616463\n",
      "Epoch 243 loss: 0.7473140232264995 val_loss: 0.43648997247219085\n",
      "Epoch 244 loss: 0.7530929258093237 val_loss: 0.4429090291261673\n",
      "Epoch 245 loss: 0.7482326423749328 val_loss: 0.4555783629417419\n",
      "Epoch 246 loss: 0.7405838454142213 val_loss: 0.459952774643898\n",
      "Epoch 247 loss: 0.7497633393853903 val_loss: 0.4520661547780037\n",
      "Epoch 248 loss: 0.7360994471237063 val_loss: 0.45239324271678927\n",
      "Epoch 249 loss: 0.7409518454223871 val_loss: 0.46316423267126083\n",
      "Epoch 250 loss: 0.7396497339010238 val_loss: 0.4543890580534935\n",
      "Epoch 251 loss: 0.7288762714713812 val_loss: 0.45097584575414656\n",
      "Epoch 252 loss: 0.7322811553254723 val_loss: 0.45422996431589124\n",
      "Epoch 253 loss: 0.7474348032847047 val_loss: 0.44328598529100416\n",
      "Epoch 254 loss: 0.7413120530545712 val_loss: 0.46317155957221984\n",
      "Epoch 255 loss: 0.7404341462999582 val_loss: 0.46981133371591566\n",
      "Epoch 256 loss: 0.733188065700233 val_loss: 0.4557762145996094\n",
      "Epoch 257 loss: 0.7252857541665435 val_loss: 0.449288210272789\n",
      "Epoch 258 loss: 0.7316032227128744 val_loss: 0.4605736717581749\n",
      "Epoch 259 loss: 0.7423293007537722 val_loss: 0.47438703328371046\n",
      "Epoch 260 loss: 0.7450162311084568 val_loss: 0.45144163221120837\n",
      "Epoch 261 loss: 0.7331887729465961 val_loss: 0.45341223031282424\n",
      "Epoch 262 loss: 0.7421310009434819 val_loss: 0.45130297988653184\n",
      "Epoch 263 loss: 0.7315761700272561 val_loss: 0.45986891239881517\n",
      "Epoch 264 loss: 0.7285688830539584 val_loss: 0.4560100585222244\n",
      "Epoch 265 loss: 0.7420370269566774 val_loss: 0.45902675539255144\n",
      "Epoch 266 loss: 0.7252402795478702 val_loss: 0.4650050848722458\n",
      "Epoch 267 loss: 0.7173961261287332 val_loss: 0.4661268785595894\n",
      "Epoch 268 loss: 0.7240687692537904 val_loss: 0.45015649050474166\n",
      "Epoch 269 loss: 0.7349893435835838 val_loss: 0.465708327293396\n",
      "Epoch 270 loss: 0.7283665893599391 val_loss: 0.4788484379649162\n",
      "Epoch 271 loss: 0.7325545748695731 val_loss: 0.46281431168317794\n",
      "Epoch 272 loss: 0.7386335831135511 val_loss: 0.4649863809347153\n",
      "Epoch 273 loss: 0.7385770490393042 val_loss: 0.4630772516131401\n",
      "Epoch 274 loss: 0.7297148505225778 val_loss: 0.44948389530181887\n",
      "Epoch 275 loss: 0.7663380732759834 val_loss: 0.42558510005474093\n",
      "Epoch 276 loss: 0.7491768181324006 val_loss: 0.45717606097459795\n",
      "Epoch 277 loss: 0.7335621941834688 val_loss: 0.46940028220415114\n",
      "Epoch 278 loss: 0.7504863468930125 val_loss: 0.4495297774672508\n",
      "Epoch 279 loss: 0.7813023753464222 val_loss: 0.4355196386575699\n",
      "Epoch 280 loss: 0.7746006481349468 val_loss: 0.41223572939634323\n",
      "Epoch 281 loss: 0.7475511405616999 val_loss: 0.4378897130489349\n",
      "Epoch 282 loss: 0.7503102300688624 val_loss: 0.43215213865041735\n",
      "Epoch 283 loss: 0.7525505520403385 val_loss: 0.44303260892629626\n",
      "Epoch 284 loss: 0.7229676965624094 val_loss: 0.4618952885270119\n",
      "Epoch 285 loss: 0.7210059912875295 val_loss: 0.4612921342253685\n",
      "Epoch 286 loss: 0.7363353809341788 val_loss: 0.44865615516901014\n",
      "Epoch 287 loss: 0.723278271779418 val_loss: 0.472380293905735\n",
      "Epoch 288 loss: 0.7154310325160622 val_loss: 0.4572260931134224\n",
      "Epoch 289 loss: 0.7214335288852454 val_loss: 0.447462785243988\n",
      "Epoch 290 loss: 0.7267229720950127 val_loss: 0.4523155465722084\n",
      "Epoch 291 loss: 0.7137409377843141 val_loss: 0.4594930186867714\n",
      "Epoch 292 loss: 0.7246938940137625 val_loss: 0.463836544752121\n",
      "Epoch 293 loss: 0.7196242704987525 val_loss: 0.4645094245672226\n",
      "Epoch 294 loss: 0.7320680087432265 val_loss: 0.46504366397857666\n",
      "Epoch 295 loss: 0.7272487953305244 val_loss: 0.45171337723731997\n",
      "Epoch 296 loss: 0.7268177697435021 val_loss: 0.4584163650870323\n",
      "Epoch 297 loss: 0.7172164022922516 val_loss: 0.4601759687066078\n",
      "Epoch 298 loss: 0.7081662813201547 val_loss: 0.4716564521193504\n",
      "Epoch 299 loss: 0.7149752231314779 val_loss: 0.4794676974415779\n",
      "Epoch 300 loss: 0.7035726113244891 val_loss: 0.4624773278832436\n",
      "Epoch 301 loss: 0.7148173216730356 val_loss: 0.45986240953207014\n",
      "Epoch 302 loss: 0.7306637806817889 val_loss: 0.46225220412015916\n",
      "Epoch 303 loss: 0.7266522325575352 val_loss: 0.4518790304660797\n",
      "Epoch 304 loss: 0.7208364171907305 val_loss: 0.4485595941543579\n",
      "Epoch 305 loss: 0.710284435749054 val_loss: 0.45726055949926375\n",
      "Epoch 306 loss: 0.7103756342083216 val_loss: 0.4658113270998001\n",
      "Epoch 307 loss: 0.7149241857230664 val_loss: 0.45138547718524935\n",
      "Epoch 308 loss: 0.708497473038733 val_loss: 0.4774091109633446\n",
      "Epoch 309 loss: 0.7235874766483903 val_loss: 0.46377418339252474\n",
      "Epoch 310 loss: 0.7278074750676751 val_loss: 0.46470846235752106\n",
      "Epoch 311 loss: 0.7184559779241682 val_loss: 0.47196345031261444\n",
      "Epoch 312 loss: 0.7229316772893071 val_loss: 0.4564423844218254\n",
      "Epoch 313 loss: 0.7109662923961878 val_loss: 0.4653304725885391\n",
      "Epoch 314 loss: 0.7179292563349009 val_loss: 0.4613321587443352\n",
      "Epoch 315 loss: 0.7223842550069094 val_loss: 0.45132972598075866\n",
      "Epoch 316 loss: 0.7219767386093736 val_loss: 0.45723415315151217\n",
      "Epoch 317 loss: 0.7118250031024218 val_loss: 0.45631484538316724\n",
      "Epoch 318 loss: 0.7195778613910079 val_loss: 0.45640513896942136\n",
      "Epoch 319 loss: 0.7166750313714146 val_loss: 0.4740978702902794\n",
      "Epoch 320 loss: 0.7234599851071835 val_loss: 0.4604309290647507\n",
      "Epoch 321 loss: 0.7092158762738109 val_loss: 0.45197543501853943\n",
      "Epoch 322 loss: 0.7055294694378972 val_loss: 0.470969420671463\n",
      "Epoch 323 loss: 0.7082867888733745 val_loss: 0.45266063809394835\n",
      "Epoch 324 loss: 0.7157517621293664 val_loss: 0.47221368700265887\n",
      "Epoch 325 loss: 0.7086211141198874 val_loss: 0.47499738037586214\n",
      "Epoch 326 loss: 0.7129396317526698 val_loss: 0.44841925501823426\n",
      "Epoch 327 loss: 0.7160928264260292 val_loss: 0.44335374534130095\n",
      "Epoch 328 loss: 0.724657909758389 val_loss: 0.4580427572131157\n",
      "Epoch 329 loss: 0.7031834838911891 val_loss: 0.472259658575058\n",
      "Epoch 330 loss: 0.7037851369008422 val_loss: 0.48486056476831435\n",
      "Epoch 331 loss: 0.7073235172778368 val_loss: 0.4681528747081757\n",
      "Epoch 332 loss: 0.711648123152554 val_loss: 0.47480721324682235\n",
      "Epoch 333 loss: 0.7063516717404127 val_loss: 0.4520587056875229\n",
      "Epoch 334 loss: 0.7003534689545632 val_loss: 0.4826810881495476\n",
      "Epoch 335 loss: 0.7144830884411931 val_loss: 0.49726574718952177\n",
      "Epoch 336 loss: 0.7111612293869257 val_loss: 0.45789096802473067\n",
      "Epoch 337 loss: 0.7233983304351568 val_loss: 0.44537400752305983\n",
      "Epoch 338 loss: 0.7648948054760695 val_loss: 0.43383549302816393\n",
      "Epoch 339 loss: 0.7290261030197144 val_loss: 0.44169282764196394\n",
      "Epoch 340 loss: 0.720840984210372 val_loss: 0.45934993773698807\n",
      "Epoch 341 loss: 0.735928962379694 val_loss: 0.4529560223221779\n",
      "Epoch 342 loss: 0.7256273034960031 val_loss: 0.480286018550396\n",
      "Epoch 343 loss: 0.7025617074221373 val_loss: 0.4733083963394165\n",
      "Epoch 344 loss: 0.702735330350697 val_loss: 0.47130855470895766\n",
      "Epoch 345 loss: 0.7015450283885002 val_loss: 0.46454476863145827\n",
      "Epoch 346 loss: 0.7020164398476482 val_loss: 0.4758114218711853\n",
      "Epoch 347 loss: 0.7004513498395681 val_loss: 0.48631811141967773\n",
      "Epoch 348 loss: 0.6981967903673649 val_loss: 0.45800833255052564\n",
      "Epoch 349 loss: 0.7075758971273899 val_loss: 0.4676686584949493\n",
      "Epoch 350 loss: 0.6923991719260811 val_loss: 0.4729312539100647\n",
      "Epoch 351 loss: 0.7046683838590979 val_loss: 0.46467232406139375\n",
      "Epoch 352 loss: 0.694501543790102 val_loss: 0.46484249383211135\n",
      "Epoch 353 loss: 0.6904651448130608 val_loss: 0.47399899214506147\n",
      "Epoch 354 loss: 0.6945349389687181 val_loss: 0.47616612166166306\n",
      "Epoch 355 loss: 0.7208806863054633 val_loss: 0.4824053466320038\n",
      "Epoch 356 loss: 0.7082675274461507 val_loss: 0.4825830698013306\n",
      "Epoch 357 loss: 0.7071475079283118 val_loss: 0.4535882085561752\n",
      "Epoch 358 loss: 0.6990094697102904 val_loss: 0.47971270233392715\n",
      "Epoch 359 loss: 0.7068069810047746 val_loss: 0.4672782778739929\n",
      "Epoch 360 loss: 0.706913728453219 val_loss: 0.45769732594490053\n",
      "Epoch 361 loss: 0.6918346807360649 val_loss: 0.4736956611275673\n",
      "Epoch 362 loss: 0.6907016210258007 val_loss: 0.4782881662249565\n",
      "Epoch 363 loss: 0.6980419483035802 val_loss: 0.46156401187181473\n",
      "Epoch 364 loss: 0.6969860570505262 val_loss: 0.455630898475647\n",
      "Epoch 365 loss: 0.6982322845607996 val_loss: 0.48110961467027663\n",
      "Epoch 366 loss: 0.6926095558330416 val_loss: 0.4678871646523476\n",
      "Epoch 367 loss: 0.6995768176391721 val_loss: 0.4802327588200569\n",
      "Epoch 368 loss: 0.6929544404149055 val_loss: 0.46767280250787735\n",
      "Epoch 369 loss: 0.6938652398064733 val_loss: 0.46308192759752276\n",
      "Epoch 370 loss: 0.7068179681897163 val_loss: 0.4679827854037285\n",
      "Epoch 371 loss: 0.6980580704286694 val_loss: 0.47829491794109347\n",
      "Epoch 372 loss: 0.6938528364524246 val_loss: 0.48080732077360155\n",
      "Epoch 373 loss: 0.7041278664022684 val_loss: 0.47934380173683167\n",
      "Epoch 374 loss: 0.696606975607574 val_loss: 0.4602357536554337\n",
      "Epoch 375 loss: 0.6889423551037908 val_loss: 0.479486420750618\n",
      "Epoch 376 loss: 0.683302160538733 val_loss: 0.4797739237546921\n",
      "Epoch 377 loss: 0.6854071792215108 val_loss: 0.480017626285553\n",
      "Epoch 378 loss: 0.682188518717885 val_loss: 0.4827713072299957\n",
      "Epoch 379 loss: 0.6926865542307497 val_loss: 0.4672211617231369\n",
      "Epoch 380 loss: 0.6855181830003858 val_loss: 0.47030960470438005\n",
      "Epoch 381 loss: 0.6972737880423665 val_loss: 0.46213532984256744\n",
      "Epoch 382 loss: 0.6916671527549625 val_loss: 0.48029494285583496\n",
      "Epoch 383 loss: 0.68434565551579 val_loss: 0.47026666849851606\n",
      "Epoch 384 loss: 0.6815712321549654 val_loss: 0.4862832084298134\n",
      "Epoch 385 loss: 0.7075940916314721 val_loss: 0.4614328071475029\n",
      "Epoch 386 loss: 0.7045623248443007 val_loss: 0.47897113859653473\n",
      "Epoch 387 loss: 0.7071170071139932 val_loss: 0.46753534823656084\n",
      "Epoch 388 loss: 0.7003470070660114 val_loss: 0.46323823779821394\n",
      "Epoch 389 loss: 0.6767142657190561 val_loss: 0.4839437663555145\n",
      "Epoch 390 loss: 0.6806400788947939 val_loss: 0.4805847629904747\n",
      "Epoch 391 loss: 0.6869171837344765 val_loss: 0.4718511551618576\n",
      "Epoch 392 loss: 0.6808822140097618 val_loss: 0.47670744359493256\n",
      "Epoch 393 loss: 0.680708478577435 val_loss: 0.495402193069458\n",
      "Epoch 394 loss: 0.6840928979218006 val_loss: 0.47945455461740494\n",
      "Epoch 395 loss: 0.6842979960143566 val_loss: 0.4576147750020027\n",
      "Epoch 396 loss: 0.6940541779622436 val_loss: 0.4927761197090149\n",
      "Epoch 397 loss: 0.6848789721727371 val_loss: 0.4848792925477028\n",
      "Epoch 398 loss: 0.6926606100052595 val_loss: 0.47755031287670135\n",
      "Epoch 399 loss: 0.682851835899055 val_loss: 0.4874565422534943\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from modulus.launch.utils import save_checkpoint, load_checkpoint\n",
    "checkpoint_path = 'checkpoints'\n",
    "os.makedirs(checkpoint_path,exist_ok=True)\n",
    "epoch_init = load_checkpoint(checkpoint_path,model,optimizer,scheduler,scaler,device=device)\n",
    "num_epochs = 400\n",
    "model.to(device)\n",
    "\n",
    "def compute_loss(batch):\n",
    "    batch = batch.to(device)\n",
    "    node_X, edge_X = get_node_edge_X(batch)\n",
    "    node_Y = get_node_Y(batch)\n",
    "    node_Y_pred = model(node_X,edge_X,batch)\n",
    "    batch_pred_graph = batch.clone()\n",
    "    set_graph_features(batch_pred_graph, node_X, edge_X, node_Y_pred)\n",
    "    agg_force_pred = ds_dgl.compute_aggregate_force(batch_pred_graph)\n",
    "    agg_force = ds_dgl.compute_aggregate_force(batch)\n",
    "    #print('Agg force pred: ',format_vector(agg_force_pred.tolist()),' Agg force: ',format_vector(agg_force.tolist()))\n",
    "    return torch.nn.functional.mse_loss(node_Y_pred,node_Y) + 5* torch.nn.functional.mse_loss(agg_force_pred,agg_force)\n",
    "for epoch in range(epoch_init,num_epochs):\n",
    "    total_loss = 0\n",
    "    for batch in dataloader:\n",
    "        loss = compute_loss(batch)\n",
    "        total_loss += loss.item()\n",
    "        optimizer.zero_grad()\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "    total_loss /= len(train_ds)\n",
    "    total_loss = total_loss\n",
    "    val_loss = 0\n",
    "    for batch in val_dataloader:\n",
    "        val_loss += compute_loss(batch).item()\n",
    "    val_loss /= len(val_ds)\n",
    "    print(f'Epoch {epoch} loss: {total_loss} val_loss: {val_loss}')\n",
    "    scheduler.step()\n",
    "    if epoch % 10 == 0:\n",
    "        save_checkpoint(checkpoint_path,model,optimizer,scheduler,scaler,epoch)\n",
    "save_checkpoint(checkpoint_path,model,optimizer,scheduler,scaler,num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26ad378c69b243ecbdc12c77e90808db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Widget(value='<iframe src=\"http://localhost:36067/index.html?ui=P_0x707f30409610_3&reconnect=auto\" class=\"pyvi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.to(device)\n",
    "g=ds_dgl[0].to(device)\n",
    "g_pred = g.clone().to(device)\n",
    "ndx, edx = get_node_edge_X(g)\n",
    "with torch.no_grad():\n",
    "    y_pred = model(ndx,edx,g)\n",
    "set_graph_features(g_pred, ndx, edx, y_pred)\n",
    "ds_dgl.plot_surface(g_pred,\"Pressure\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b6d5ad78f304c2da68979ce978af36c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Widget(value='<iframe src=\"http://localhost:36067/index.html?ui=P_0x707e7a5a8050_4&reconnect=auto\" class=\"pyvi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds_dgl.plot_surface(g,\"Pressure\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0015, -0.0008, -0.0011], device='cuda:0')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_dgl.compute_aggregate_force(g, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0084,  0.0056, -0.1487], device='cuda:0')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_dgl.compute_aggregate_force(g_pred,1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
